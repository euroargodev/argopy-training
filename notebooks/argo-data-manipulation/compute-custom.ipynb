{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1b9c837-bb0b-47f3-a756-9737fa99659d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/euroargodev/argopy/master/docs/_static/argopy_logo_long.png\" alt=\"argopy logo\" width=\"200\"/>\n",
    "\n",
    "# Training Camp - Sept 22<sup>th</sup> 2025\n",
    "\n",
    "***\n",
    "\n",
    "## Notebook Title : Compute your own per-profile diagnostic\n",
    "\n",
    "**Author contact : [G. Maze](https://annuaire.ifremer.fr/cv/17182)**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This notebook shows how to complement an existing Argo data dataset with your own per-profile diagnostic.\n",
    "\n",
    "The [Dataset.argo.reduce_profile()](https://argopy.readthedocs.io/en/v1.3.0/generated/xarray.Dataset.argo.reduce_profile.html#xarray.Dataset.argo.reduce_profile) method allows to execute a per profile diagnostic function very efficiently. \n",
    "\n",
    "Such a diagnostic function **takes vertical profiles as input and return a single value as output** (see examples below). Typical usage example would include computation of mixed layer depth or euphotic layer depth.\n",
    "\n",
    "This is a notebook exploring this [section of the Argopy documentation](https://argopy.readthedocs.io/en/v1.3.0/user-guide/working-with-argo-data/data_computation.html#per-profile-custom-diagnostic).\n",
    "\n",
    "*This notebook was developed with Argopy version: 1.3*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253500e-9e2f-4a60-afeb-b236e1fd99f5",
   "metadata": {},
   "source": [
    "Let's start with some import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b0572-2fcc-459d-ad8e-1589eeb24f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argopy import DataFetcher\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c7008-fa70-497f-9ae8-33cf697e5834",
   "metadata": {},
   "source": [
    "And to prevent cell output to be too large, we won't display xarray object attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f25f46-fb21-40f2-90b7-0ee9d213fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "xr.set_options(display_expand_attrs = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0dd2e-b93a-4755-8326-7db3ef57c212",
   "metadata": {},
   "source": [
    "### Execute a diagnostic without options\n",
    "\n",
    "The most simple example is when the diagnostic method does not need arguments.\n",
    "\n",
    "To illustrate this, let's apply a diagnostic that computes the mixed layer depth for a profile.\n",
    "\n",
    "Such a diagnostic could be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a088e0-4a45-433f-a663-f7ada2a2f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_mld(pres, sig0):\n",
    "    \"\"\"Return MLD with Boyer Mont\u00e9gut method with threshold of \u03c3(10m) + 0.03 kg.m-3\"\"\"\n",
    "    # Reference values\n",
    "    threshold, threshold_depth = 0.03, 10.\n",
    "    \n",
    "    # Filter out NaN values\n",
    "    idx = ~np.logical_or(np.isnan(pres), np.isnan(sig0))\n",
    "    sig0_depth, sig0 = pres[idx], sig0[idx]\n",
    "\n",
    "    # Check if there are valid data points near the reference depth\n",
    "    if not np.any((sig0_depth >= 0) & (sig0_depth <= threshold_depth)):\n",
    "        return np.nan\n",
    "\n",
    "    # Get the reference density at the threshold depth\n",
    "    index_threshold = np.argmin(np.abs(sig0_depth - threshold_depth))\n",
    "    sig0_at_threshold = sig0[index_threshold]\n",
    "\n",
    "    # Find the first depth where density exceeds the threshold\n",
    "    exceeds_threshold = sig0[index_threshold:] > sig0_at_threshold + threshold\n",
    "    if not np.any(exceeds_threshold):\n",
    "        return np.nan\n",
    "\n",
    "    mld_index = np.where(exceeds_threshold)[0][0] + index_threshold\n",
    "    return sig0_depth[mld_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab9b84-804e-46c7-8010-70293ed1bbf3",
   "metadata": {},
   "source": [
    "\ud83d\udedf It is important to note that the per-profile diagnostic will receive 1-dimensional arrays of one profile data, not xarray object. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d40170-c295-475d-a49e-179a7c27b5cd",
   "metadata": {},
   "source": [
    "Then to apply the diagnostic to a collection of Argo profile, let's first load data from a region just South of the Gulf Stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b43ba-fba7-4991-b2f1-a02e8e3be808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f = DataFetcher().region([-69., -64., 32., 36., 0., 1000., '20200101', '20230101'])\n",
    "ds = f.data\n",
    "ds.argo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aca611-cb5a-4886-b75d-49f7cd58921e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "and convert this collection of points to a collection of profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c164af-d42d-4dea-97f5-7ea376eb7c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp = ds.argo.point2profile()\n",
    "dsp.argo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269f1c2f-71a2-4067-845e-43b15d1aa4ad",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We note that the `diag_mld` method above, takes pressure and potential density as arguments, in this order.\n",
    "\n",
    "Argopy and xarray will handle all the axis and dimensions manipulation, so that you can focus on writing a reducer function dealing with 1D arrays for each requested parameters.\n",
    "\n",
    "So, to apply this diagnostic to the xarray Argo dataset, we first need to compute SIG0 and then we can call the reducer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58364501-4d2d-41fd-b959-711575e61dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dsp.argo.teos10(['SIG0']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc490d-e59d-47e4-83df-cefc888e00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dsp['MLD'] = dsp.argo.reduce_profile(diag_mld, params=['PRES', 'SIG0'])\n",
    "dsp['MLD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d9d956-af78-48f0-919c-6c96cb291b2c",
   "metadata": {},
   "source": [
    "#### \ud83d\udedf Note\n",
    "\n",
    "Note that the new variable has the appropriate dimension `N_PROF` and coordinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e3dba9-412a-40da-a1f0-76858f5244a5",
   "metadata": {},
   "source": [
    "#### \ud83d\udd0d Pro tip\n",
    "\n",
    "You can add attributes to the new variable and you can plot it along the dataset potential density like this:\n",
    "\n",
    "(easier methods shall be developped in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc66d6-de6d-420f-99fc-a200c06b84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp['MLD'].attrs = {'unit': 'db',\n",
    "                   'long_name': 'Mixed Layer Depth',\n",
    "                   'method': 'Density threshold'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719391a-55e5-4833-8654-eda33ee374d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argopy.plot import scatter_plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax, _, _ = scatter_plot(dsp, 'SIG0', cmap='Spectral_r', s=12, cbar=True);\n",
    "ax.plot(dsp['TIME'], dsp['MLD'], 'k', label=dsp['MLD'].attrs['long_name'])\n",
    "ax.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb457aa-b74d-4c7e-8e5e-7a22fa126c87",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#### \u270f\ufe0f EXERCICE\n",
    "\n",
    "Write down a function computing the oxygen minimum depth and apply it to some BGC-Argo dataset.\n",
    "\n",
    "\ud83d\udca1 Code hint: \n",
    "```python\n",
    "def min_oxygen_depth(pres, doxy):    \n",
    "    idx = ~np.logical_or(np.isnan(pres), np.isnan(doxy))  # Filter out NaN values\n",
    "    return ...\n",
    "\n",
    "f = DataFetcher(ds='bgc', params='DOXY').float(6903222)\n",
    "dsp = f.data.argo.point2profile()\n",
    "dsp...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c08a8d-fbe8-4b99-b6ee-0ed628f0c907",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9ce50-8385-4848-bdf4-55c51c9c301c",
   "metadata": {},
   "source": [
    "### Execute a diagnostic with options\n",
    "\n",
    "In a more realistic scenario, it will be often the case that your diagnostic will require options to play around with some parameters.\n",
    "\n",
    "**To add options to your diagnostic, just add them as named arguments to the method and provide them to the Argopy reducer.**\n",
    "\n",
    "To illustrate this, let's take a diagnostic method that computes the depth of an isothermal surface, which should be given as an option.\n",
    "\n",
    "It could go like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0dcd9a-7e49-4db4-bec9-8c6579d4090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isoT_depth(pres, temp, iso = 12.):\n",
    "    idx = ~np.logical_or(np.isnan(pres), np.isnan(temp))\n",
    "    idx_top, idx_btm = temp[idx] >= iso, temp[idx] <= iso\n",
    "    if np.any(idx_top):\n",
    "        i_top, i_btm = np.max(np.argwhere(idx_top)), np.min(np.argwhere(idx_btm))\n",
    "        t_top, p_top, t_btm, p_btm = temp[i_top], pres[i_top], temp[i_btm], pres[i_btm]\n",
    "        return p_top + (p_btm-p_top)*(t_top-isotemp)/(t_top-t_btm)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b4043-c898-4ade-81e4-7a2035fe9bf0",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's download and transform some float data to illustrate this diagnostic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e24a1-ce0a-492a-8e8c-9e58b36b419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "f = DataFetcher().float(6902915)  # A float in the North Atlantic subtropical gyre\n",
    "dsp = f.data.argo.point2profile()\n",
    "dsp.argo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424afbc3-cc14-4083-ac3f-f82d3d30b9f2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Let's now apply the diagnostic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d915ef0-8b7c-433f-a8d3-f60c2043a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "isotemp = 26.  # Isothermal surface target, in degree Celsius\n",
    "\n",
    "da = dsp.argo.reduce_profile(isoT_depth, params=['PRES', 'TEMP'], iso=isotemp)\n",
    "da.attrs = {'unit': 'db',\n",
    "            'long_name': f\"TEMP={isotemp}^oC depth\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb21f83-5fc3-4b91-9728-687c5b1b5d42",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Add the new variable to the Argo dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7cfed0-ff30-47c5-8022-d633fa109299",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsp['isoT'] = da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142cd96-f617-469b-877b-a5a6b2626217",
   "metadata": {},
   "source": [
    "#### \ud83d\udd0d Pro tip\n",
    "\n",
    "You can plot the new variable like this:\n",
    "\n",
    "(easier methods shall be developped in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73f10f-b1ae-4620-86b3-69ededba5e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argopy.plot import scatter_plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax, _, _ = scatter_plot(dsp, 'TEMP', cmap='Spectral_r', s=6, vmin=isotemp-2, vmax=isotemp+2, cbar=1);\n",
    "ax.plot(dsp['TIME'], dsp['isoT'], 'k', label=dsp['isoT'].attrs['long_name'])\n",
    "ax.set_ylim([np.nanmax(dsp['isoT'])+200, 0])\n",
    "ax.legend(loc='lower left');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3301ed8a-bc5c-4b43-94a5-070e209a4482",
   "metadata": {},
   "source": [
    "#### \u270f\ufe0f EXERCICE\n",
    "\n",
    "Getting back to the mixed layer depth diagnostic, the density reference level and threshold could be options easily accessible for a more appropriate diagnostic.\n",
    "\n",
    "Modify the `diag_mld` method to take reference values as option and demonstrate its use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec65300-08c6-4be7-8981-1609b6e3d0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff06054-69f0-4baf-ac7f-2aab6f48ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e2c5b2-ad25-4553-a120-92e8b1d3ca1a",
   "metadata": {},
   "source": [
    "### Optimise slow diagnostics with Dask\n",
    "\n",
    "Using a [Dask cluster](https://docs.dask.org/en/stable/deploying.html), chunking your dataset along the `N_PROF` dimension will make Argopy and xarray to execute the diagnostic on each chunk of profile in parallel.\n",
    "\n",
    "\ud83d\udd0d In particular, if your diagnostic is rather slow to execute on a single profile, you can optimise the execution on making chunks rather small, i.e. with a small amount of profiles.\n",
    "\n",
    "To illustrate this, let's first create a simple local Dask cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7377c7-c923-4aa4-88a5-7f4d221376a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ee70-f5ee-49ba-b3c4-652b98096a22",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Download some dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe07d1-5ddc-47c9-a2b1-fbbb039c1ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = DataFetcher().float(6902915)  # A float in the North Atlantic subtropical gyre\n",
    "dsp = f.data.argo.point2profile()\n",
    "dsp.argo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a28b0-72cd-4d6d-ba82-490b51931b81",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "and to trigger parallelisation, we also chunk the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5486ef-187e-47ad-b1b0-87cefcd95297",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10  # Nb of profiles per chunk\n",
    "dsp = dsp.chunk({'N_PROF': chunk_size})\n",
    "dsp['PRES'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3961645-9d4e-4ae9-a474-37bdbb72d519",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We now create a dummy diagnostic, that will artificially be long to execute with a time sleep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee364de7-4f34-48fd-8d86-3effa07ed1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def dummy(pres, temp, wait=1.):\n",
    "    time.sleep(wait)\n",
    "    return temp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c629757-6a18-45a4-bd4f-2ffe89eda5ec",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Execute the diagnostic and look at the Dask client dashboard to monitor the parallelisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48bbbdd-5b2e-464b-bdcc-7762a9e9588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wait = 0.3  # per-profile waiting time, in seconds\n",
    "dsp.argo.reduce_profile(dummy, params=['PRES', 'TEMP'], wait=wait).compute();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390595e8-e065-4357-b601-8984636eb58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In parallel, each chunk of profiles will need about:\n",
    "chunk_size * wait  # seconds to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04c1a9-e36a-4ab1-b565-60cd076bf543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the number of streams that will receive the flow of chunks is:\n",
    "n_stream = sum([value for key, value in client.nthreads().items()])\n",
    "\n",
    "# Each stream will thus receive about p chunks:\n",
    "p = len(dsp['PRES'].chunks[0])/n_stream\n",
    "\n",
    "# So each stream should last about, an indication of the overall execution time in parallel:\n",
    "chunk_size * wait * p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b5fcd-1d1a-40d8-8c97-9dcec852e7a7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "If the diagnostic was executed sequentially, we would need to wait at least `N_PROF x wait` seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7693b-2a77-4860-a7b1-6be15ec84c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dsp['N_PROF']) * wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08744660-144f-47a8-93ee-3edfa479ea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove chunking:\n",
    "dsp = dsp.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864900f0-9ef8-4f2c-9889-c567f681ee0b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "and execute the diagnostic sequentially on all profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e46eb65-ef20-4f3a-893d-41c3b6fcd2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dsp.argo.reduce_profile(dummy, params=['PRES', 'TEMP'], wait=wait);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f5d53-0baa-43f8-8124-152820ace785",
   "metadata": {
    "tags": [
     "disclaimer"
    ]
   },
   "source": [
    "### \n",
    "***\n",
    "Useful argopy commands:\n",
    "```python\n",
    "argopy.reset_options()\n",
    "argopy.show_options()\n",
    "argopy.status()\n",
    "argopy.clear_cache()\n",
    "argopy.show_versions()\n",
    "```\n",
    "***\n",
    "![logo](https://raw.githubusercontent.com/euroargodev/argopy-training/refs/heads/main/for_nb_producers/template_argopy_training_EAONE.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4792fdc8-aafc-42fa-b3ba-033a3f22416f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "argopy-training",
   "language": "python",
   "name": "argopy-training"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}